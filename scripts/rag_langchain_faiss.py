# Avec d√©tection ville automatique

# rag_langchain_faiss.py avec d√©tection automatique des villes
# === rag_langchain_faiss.py ===

# === rag_langchain_faiss.py ===
# Version avec d√©tection automatique des villes pr√©sentes dans l'index

import os
import faiss
import pickle
import time
from datetime import datetime, timedelta
from dateutil.parser import parse as parse_date
from langchain_community.vectorstores import FAISS
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_core.embeddings import Embeddings
from mistralai import Mistral
from mistralai.models import SDKError
from app_config import MISTRAL_API_KEY


# ================================
# 1Ô∏è‚É£ CLASSE PERSONNALIS√âE : Mistral Embedding AVEC RETRY
# ================================
class MistralEmbedding(Embeddings):
    """Classe d'embeddings avec gestion robuste des rate limits."""

    def __init__(self, api_key: str):
        self.client = Mistral(api_key=api_key)

    def embed_documents(self, texts, max_retries=5):
        """Embed une liste de textes avec gestion des rate limits."""
        batch_size = 32
        embeddings = []

        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            for attempt in range(max_retries):
                try:
                    response = self.client.embeddings.create(
                        model="mistral-embed",
                        inputs=batch
                    )
                    embeddings.extend([d.embedding for d in response.data])
                    print(f"‚úÖ Batch {i // batch_size + 1} trait√© ({len(batch)} textes)")
                    break
                except SDKError as e:
                    if any(err in str(e) for err in ["service_tier_capacity_exceeded", "rate_limited", "429"]):
                        wait_time = 2 ** attempt + 5
                        print(f"‚ö†Ô∏è Rate limit batch, attente {wait_time}s... (tentative {attempt + 1}/{max_retries})")
                        time.sleep(wait_time)
                    else:
                        raise e
        return embeddings

    def embed_query(self, text, max_retries=5):
        """Embed une requ√™te avec retry automatique."""
        for attempt in range(max_retries):
            try:
                response = self.client.embeddings.create(
                    model="mistral-embed",
                    inputs=[text]
                )
                return response.data[0].embedding
            except SDKError as e:
                if any(err in str(e) for err in ["service_tier_capacity_exceeded", "rate_limited", "429"]):
                    wait_time = 2 ** attempt + 2
                    print(f"‚ö†Ô∏è Rate limit query, attente {wait_time}s... (tentative {attempt + 1}/{max_retries})")
                    time.sleep(wait_time)
                else:
                    raise e
        raise Exception("üö´ √âchec query apr√®s plusieurs tentatives")


# ================================
# 2Ô∏è‚É£ CONFIGURATION
# ================================
INDEX_DIR = os.path.join("data", "processed", "faiss_indexes")
embedding_function = MistralEmbedding(api_key=MISTRAL_API_KEY)


# ================================
# 3Ô∏è‚É£ CHARGEMENT DES INDEX
# ================================
def load_faiss_index(index_name: str, embedding_function):
    index_path = os.path.join(INDEX_DIR, f"{index_name}.index")
    metadata_path = os.path.join(INDEX_DIR, f"{index_name}_metadata.pkl")

    if not os.path.exists(index_path) or not os.path.exists(metadata_path):
        raise FileNotFoundError(f"‚ùå Fichiers manquants pour {index_name}")

    index = faiss.read_index(index_path)
    with open(metadata_path, "rb") as f:
        documents = pickle.load(f)

    docstore = InMemoryDocstore({str(i): doc for i, doc in enumerate(documents)})
    index_to_docstore_id = {i: str(i) for i in range(len(documents))}

    vectorstore = FAISS(
        embedding_function=embedding_function,
        index=index,
        docstore=docstore,
        index_to_docstore_id=index_to_docstore_id,
    )

    print(f"‚úÖ Index '{index_name}' charg√© avec {len(documents)} documents.")
    return vectorstore


# ================================
# 4Ô∏è‚É£ EXTRACTION AUTOMATIQUE DES VILLES
# ================================
def extract_unique_cities(vectorstores):
    """Extrait automatiquement toutes les villes contenues dans les m√©tadonn√©es FAISS."""
    cities = set()
    for vs in vectorstores:
        for _, doc in vs.docstore._dict.items():
            city = doc.metadata.get("city")
            if city:
                cities.add(city.lower().strip())
    print(f"üèôÔ∏è {len(cities)} villes d√©tect√©es automatiquement : {list(cities)[:10]} ...")
    return list(cities)


# ================================
# 5Ô∏è‚É£ FONCTIONS DE FILTRAGE INTELLIGENT
# ================================
def parse_query(query: str, available_cities):
    """Extrait automatiquement la ville et la temporalit√© √† partir de la requ√™te utilisateur."""
    q = query.lower()
    city = next((c for c in available_cities if c in q), None)

    now = datetime.now()
    if "ce week" in q:
        date_min, date_max = now, now + timedelta(days=7)
    elif "demain" in q:
        date_min, date_max = now + timedelta(days=1), now + timedelta(days=1)
    elif "aujourd'hui" in q:
        date_min, date_max = now, now
    elif "mois prochain" in q:
        date_min, date_max = now + timedelta(days=25), now + timedelta(days=55)
    else:
        date_min, date_max = None, None

    return city, date_min, date_max


def filter_results(results, city=None, date_min=None, date_max=None):
    """Filtre les r√©sultats par ville et p√©riode."""
    filtered = []

    for doc in results:
        meta = doc.metadata
        keep = True

        # Filtrage ville
        if city and "city" in meta:
            if city.lower() not in str(meta["city"]).lower():
                keep = False

        # Filtrage date
        if keep and date_min and "start_date" in meta:
            try:
                event_date = parse_date(meta["start_date"])
                if not (date_min <= event_date <= date_max):
                    keep = False
            except Exception:
                pass

        if keep:
            filtered.append(doc)

    return filtered


# ================================
# 6Ô∏è‚É£ TEST DU SYST√àME
# ================================
if __name__ == "__main__":
    try:
        # üîπ Chargement des index FAISS
        vs_short = load_faiss_index("index_descriptions", embedding_function)
        vs_long = load_faiss_index("index_descriptions_longues", embedding_function)

        # üîπ D√©tection automatique des villes pr√©sentes dans les m√©tadonn√©es
        available_cities = extract_unique_cities([vs_short, vs_long])

        # üîπ Exemple de requ√™te

        #query = "Spectacle danse Bordeaux"
        #query = "phtographe √† Foug√®res"
        query = "Concert de jazz √† Lyon"
        #query = "Concert de jazz"
        

        #query = "photographe √† Foug√®res"
        #query = "Tous les √©v√©nements √† Paris aujourd'hui"
        #query = "Ateliers cuisine"
        #query = "Photos"
        #query = "S√©ance photos √† Nogent"
        #query = "Concert de jazz"
        #query = "Concert de jazz √† Lyon"
        #query = "Concert de jazz √† Lyon ce weekend"
        #query = "Concert de jazz √† Paris ce weekend"
        #query = "Atelier √† La Grand-Combe"
        #query = "Atelier cuisine pour enfant √† La Grand-Combe"
        #query = "Atelier de cuisine"
        #query = "exposition photo √† paris"
        #query = "F√™te de la musique"
        #query = "Ateliers cuisine pour adultes √† Marseille"
        #query = "Exposition photo √† Paris en juin 2024"
        #query = "Spectacle de danse √† Bordeaux le mois prochain"
        #query = "√âv√©nements culturels √† Lille il y'a une semaine"
        #query = "Salon d'exposition √† Nantes"
        #query = "Concert de rock √† Nice demain"
        #query = "Festival de cin√©ma √† Toulouse ce week-end"
        #query = "Atelier peinture pour enfants √† Rennes aujourd'hui"
        #query = "Conf√©rence sur l'art contemporain √† Marseille le mois prochain"
        #query = "March√© artisanal √† Strasbourg ce week-end"
        city, date_min, date_max = parse_query(query, available_cities)

        print(f"\nüîé Requ√™te : {query}")
        print(f"‚û°Ô∏è Filtres appliqu√©s ‚Üí Ville: {city}, Dates: {date_min} ‚Üí {date_max}")

        # üîπ Recherche et filtrage
        print("\nüìÇ Recherche FAISS (descriptions courtes)...")
        results_short = vs_short.similarity_search(query, k=10)
        filtered_short = filter_results(results_short, city, date_min, date_max)

        print(f"\nüéØ {len(filtered_short)} r√©sultats pertinents apr√®s filtrage :")
        for i, doc in enumerate(filtered_short[:3], 1):
            print(f"\nüß© R√©sultat {i}:")
            print(f"üìñ {doc.page_content[:200]}...")
            print(f"üìç M√©tadonn√©es : {doc.metadata}")

    except Exception as e:
        print(f"‚ùå Erreur g√©n√©rale: {e}")
