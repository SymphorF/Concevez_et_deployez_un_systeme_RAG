'''
# generate_embeddings.py
import os
import pandas as pd
import time
from tqdm import tqdm
from mistralai import Mistral
from config import MISTRAL_API_KEY

# === Configuration ===
INPUT_CSV = "data/processed/events_clean_20251031_1155.csv"  # Ton CSV nettoy√©
OUTPUT_CSV = "data/processed/events_with_embeddings.csv"
BATCH_SAVE = 20  # Sauvegarde toutes les 20 lignes

# === Initialisation du client Mistral ===
client = Mistral(api_key=MISTRAL_API_KEY)

def embed_text(text, max_retries=5):
    """G√©n√®re l'embedding pour un texte via Mistral avec retry en cas de rate limit."""
    for i in range(max_retries):
        try:
            response = client.embeddings.create(
                model="mistral-embed",
                inputs=[text]
            )
            return response.data[0].embedding
        except Exception as e:
            err_str = str(e)
            if "rate_limited" in err_str or "Service tier capacity" in err_str:
                wait = 2 ** i  # backoff exponentiel
                print(f"Erreur rate limit ou capacit√©, attente {wait}s... retry {i+1}/{max_retries}")
                time.sleep(wait)
            else:
                print(f"Erreur embedding: {e}")
                return None
    print("√âchec apr√®s plusieurs retries")
    return None

def main():
    # Chargement du CSV nettoy√©
    df = pd.read_csv(INPUT_CSV)

    # V√©rifier que la colonne 'description' existe
    if 'description' not in df.columns:
        raise RuntimeError("Colonne 'description' introuvable dans le CSV")

    # Initialiser ou r√©cup√©rer les embeddings existants
    embeddings = df['embedding'].tolist() if 'embedding' in df.columns else []

    # G√©n√©ration des embeddings
    print("G√©n√©ration des embeddings...")
    for i, desc in enumerate(tqdm(df['description'])):
        if i < len(embeddings) and embeddings[i] is not None:
            continue  # Skip si d√©j√† g√©n√©r√©

        vec = embed_text(str(desc))
        if i < len(embeddings):
            embeddings[i] = vec
        else:
            embeddings.append(vec)

        # Sauvegarde p√©riodique
        if (i + 1) % BATCH_SAVE == 0 or (i + 1) == len(df):
            df['embedding'] = embeddings
            df.to_csv(OUTPUT_CSV, index=False)
            print(f"Sauvegarde interm√©diaire √† la ligne {i+1}")

    # Sauvegarde finale
    df['embedding'] = embeddings
    df.to_csv(OUTPUT_CSV, index=False)
    print(f"Embeddings ajout√©s et sauvegard√©s dans {OUTPUT_CSV}")

if __name__ == "__main__":
    main()
'''
















# Generation des embeddings d√©j√† fait (sans chunking)
'''
import os
import pandas as pd
import time
from tqdm import tqdm
from mistralai import Mistral
from config import MISTRAL_API_KEY

# === Configuration ===
INPUT_CSV = "data/processed/events_clean_20251103_1212.csv"
OUTPUT_CSV = "data/processed/events_with_embeddings.csv"
BATCH_SAVE = 20

# === Initialisation du client Mistral ===
client = Mistral(api_key=MISTRAL_API_KEY)

def embed_text(text, max_retries=5):
    """G√©n√®re l'embedding pour un texte via Mistral avec retry en cas de rate limit."""
    for i in range(max_retries):
        try:
            response = client.embeddings.create(
                model="mistral-embed",
                inputs=[text]
            )
            return response.data[0].embedding
        except Exception as e:
            err_str = str(e)
            if "rate_limited" in err_str or "Service tier capacity" in err_str:
                wait = 2 ** i
                print(f"‚ö†Ô∏è Rate limit ou capacit√©, attente {wait}s... (retry {i+1}/{max_retries})")
                time.sleep(wait)
            else:
                print(f"‚ùå Erreur embedding : {e}")
                return None
    print("üö´ √âchec apr√®s plusieurs retries")
    return None

def main():
    df = pd.read_csv(INPUT_CSV)

    if 'description' not in df.columns:
        raise RuntimeError("Colonne 'description' introuvable dans le CSV")

    # Cr√©e la colonne 'embedding' si absente
    if 'embedding' not in df.columns:
        df['embedding'] = [None] * len(df)

    print("üöÄ G√©n√©ration des embeddings...")
    for i in tqdm(range(len(df))):
        if pd.notna(df.loc[i, 'embedding']):
            continue  # d√©j√† calcul√©

        desc = str(df.loc[i, 'description'])
        embedding = embed_text(desc)
        df.at[i, 'embedding'] = embedding

        # Sauvegarde interm√©diaire
        if (i + 1) % BATCH_SAVE == 0:
            df.to_csv(OUTPUT_CSV, index=False)
            print(f"üíæ Sauvegarde interm√©diaire √† la ligne {i+1}")

    # Sauvegarde finale
    df.to_csv(OUTPUT_CSV, index=False)
    print(f"‚úÖ Embeddings ajout√©s et sauvegard√©s dans {OUTPUT_CSV}")

if __name__ == "__main__":
    main()
'''


















# Generation des embeddings avec chunking
'''
import os
import pandas as pd
import time
from tqdm import tqdm
from mistralai import Mistral
from langchain_text_splitters import RecursiveCharacterTextSplitter
from config import MISTRAL_API_KEY

# === Configuration ===
INPUT_CSV = "data/processed/events_clean_20251103_1212.csv"
OUTPUT_CSV = "data/processed/events_with_embeddings.csv"
BATCH_SAVE = 20

# === Initialisation du client Mistral ===
client = Mistral(api_key=MISTRAL_API_KEY)

# === Initialisation du text splitter (chunking) ===
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,      # taille de chaque segment
    chunk_overlap=50,    # chevauchement entre les segments
    separators=["\n\n", "\n", ".", "!", "?", ",", " "]  # d√©coupage logique
)

def embed_text(text, max_retries=5):
    """G√©n√®re l'embedding pour un texte via Mistral avec retry en cas de rate limit."""
    for i in range(max_retries):
        try:
            response = client.embeddings.create(
                model="mistral-embed",
                inputs=[text]
            )
            return response.data[0].embedding
        except Exception as e:
            err_str = str(e)
            if "rate_limited" in err_str or "Service tier capacity" in err_str:
                wait = 2 ** i
                print(f"‚ö†Ô∏è Rate limit ou capacit√©, attente {wait}s... (retry {i+1}/{max_retries})")
                time.sleep(wait)
            else:
                print(f"‚ùå Erreur embedding : {e}")
                return None
    print("üö´ √âchec apr√®s plusieurs retries")
    return None

def main():
    df = pd.read_csv(INPUT_CSV)

    if 'description' not in df.columns:
        raise RuntimeError("Colonne 'description' introuvable dans le CSV")

    # Cr√©e la colonne 'embedding' si absente
    if 'embedding' not in df.columns:
        df['embedding'] = [None] * len(df)

    print("üöÄ G√©n√©ration des embeddings avec chunking...")

    for i in tqdm(range(len(df))):
        if pd.notna(df.loc[i, 'embedding']):
            continue  # d√©j√† calcul√©

        desc = str(df.loc[i, 'description'])
        if not desc or desc.lower() == "nan":
            df.at[i, 'embedding'] = None
            continue

        # --- CHUNKING du texte ---
        chunks = text_splitter.split_text(desc)

        # G√©n√®re un embedding pour chaque chunk
        chunk_embeddings = []
        for chunk in chunks:
            emb = embed_text(chunk)
            if emb:
                chunk_embeddings.append(emb)
            time.sleep(0.2)  # petite pause pour √©viter le rate limit

        # Moyenne des embeddings des chunks pour repr√©senter la description compl√®te
        if chunk_embeddings:
            # moyenne sur chaque dimension du vecteur
            import numpy as np
            avg_embedding = np.mean(chunk_embeddings, axis=0).tolist()
            df.at[i, 'embedding'] = avg_embedding
        else:
            df.at[i, 'embedding'] = None

        # Sauvegarde interm√©diaire
        if (i + 1) % BATCH_SAVE == 0:
            df.to_csv(OUTPUT_CSV, index=False)
            print(f"üíæ Sauvegarde interm√©diaire √† la ligne {i+1}")

    # Sauvegarde finale
    df.to_csv(OUTPUT_CSV, index=False)
    print(f"‚úÖ Embeddings ajout√©s et sauvegard√©s dans {OUTPUT_CSV}")

if __name__ == "__main__":
    main()
'''
















# Generation des embeddings avec chunking et sleep

'''
import os
import pandas as pd
import time
import numpy as np
from tqdm import tqdm
from mistralai import Mistral
from langchain_text_splitters import RecursiveCharacterTextSplitter
from config import MISTRAL_API_KEY

# === Configuration ===
INPUT_CSV = "data/processed/events_clean_20251103_1212.csv"
OUTPUT_CSV = "data/processed/events_with_embeddings.csv"
BATCH_SAVE = 20
EMBED_SLEEP = 0.2     # D√©lai entre chaque appel API (en secondes)
MAX_RETRIES = 5

# === Modes ===
MODE_TEST = True      # üîÅ Passe √† False pour traiter TOUT le dataset
TEST_SIZE = 1000      # Nombre de lignes √† traiter en mode test

# === Initialisation du client Mistral ===
client = Mistral(api_key=MISTRAL_API_KEY)

# === Initialisation du text splitter ===
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50,
    separators=["\n\n", "\n", ".", "!", "?", ",", " "]
)

def embed_text(text, max_retries=MAX_RETRIES):
    """G√©n√®re l'embedding d'un texte via Mistral avec retries en cas de rate limit."""
    for i in range(max_retries):
        try:
            response = client.embeddings.create(
                model="mistral-embed",
                inputs=[text]
            )
            return response.data[0].embedding
        except Exception as e:
            err_str = str(e)
            if "rate_limited" in err_str or "Service tier capacity" in err_str:
                wait = 2 ** i
                print(f"‚ö†Ô∏è Rate limit ou capacit√©, attente {wait}s... (retry {i+1}/{max_retries})")
                time.sleep(wait)
            else:
                print(f"‚ùå Erreur embedding : {e}")
                return None
    print("üö´ √âchec apr√®s plusieurs retries")
    return None


def main():
    df = pd.read_csv(INPUT_CSV)

    if 'description' not in df.columns:
        raise RuntimeError("Colonne 'description' introuvable dans le CSV")

    # Mode test : limite le nombre de lignes
    if MODE_TEST:
        df = df.head(TEST_SIZE)
        print(f"üß™ Mode TEST activ√© : traitement des {len(df)} premi√®res lignes")
    else:
        print(f"üöÄ Mode COMPLET activ√© : traitement des {len(df)} lignes")

    # Cr√©e la colonne 'embedding' si absente
    if 'embedding' not in df.columns:
        df['embedding'] = [None] * len(df)

    print("‚öôÔ∏è  G√©n√©ration des embeddings avec chunking...\n")

    for i in tqdm(range(len(df))):
        if pd.notna(df.loc[i, 'embedding']):
            continue  # d√©j√† calcul√©

        desc = str(df.loc[i, 'description'])
        if not desc or desc.lower() == "nan":
            df.at[i, 'embedding'] = None
            continue

        # --- CHUNKING du texte ---
        chunks = text_splitter.split_text(desc)

        # --- G√©n√®re un embedding pour chaque chunk ---
        chunk_embeddings = []
        for chunk in chunks:
            emb = embed_text(chunk)
            if emb:
                chunk_embeddings.append(emb)
            time.sleep(EMBED_SLEEP)  # Pause entre chaque requ√™te

        # --- Moyenne des embeddings des chunks ---
        if chunk_embeddings:
            avg_embedding = np.mean(chunk_embeddings, axis=0).tolist()
            df.at[i, 'embedding'] = avg_embedding
        else:
            df.at[i, 'embedding'] = None

        # --- Sauvegarde interm√©diaire ---
        if (i + 1) % BATCH_SAVE == 0:
            df.to_csv(OUTPUT_CSV, index=False)
            print(f"üíæ Sauvegarde interm√©diaire √† la ligne {i+1}")

    # === Sauvegarde finale ===
    df.to_csv(OUTPUT_CSV, index=False)
    print(f"\n‚úÖ Embeddings ajout√©s et sauvegard√©s dans {OUTPUT_CSV}")


if __name__ == "__main__":
    main()
'''



















# G√©n√©ration des embeddings avec chunking et sleep generation embeddings sur "description" et "description_longue" (Version finale)
# generate_embeddings.py

# generate_embeddings.py

import os
import pandas as pd
import time
import numpy as np
from tqdm import tqdm
from mistralai import Mistral
from langchain_text_splitters import RecursiveCharacterTextSplitter
from config import MISTRAL_API_KEY

# === Configuration ===
#INPUT_CSV = "data/processed/events_clean_20251103_1212.csv" # Le CSV nettoy√© recup√©r√© depuis data_collected.py
INPUT_CSV = "data/processed/events_clean.csv" # Le CSV nettoy√© recup√©r√© depuis data_collected.py
OUTPUT_CSV = "data/processed/events_with_embeddings.csv"
BATCH_SAVE = 20
EMBED_SLEEP = 0.2     # D√©lai entre chaque appel API (en secondes)
MAX_RETRIES = 5

# === Modes ===
MODE_TEST = False      # üîÅ Passe √† True pour tester sur un √©chantillon
TEST_SIZE = 1000       # Nombre de lignes √† traiter en mode test

# === Initialisation du client Mistral ===
client = Mistral(api_key=MISTRAL_API_KEY)

# === Initialisation du text splitter ===
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50,
    separators=["\n\n", "\n", ".", "!", "?", ",", " "]
)


def embed_text(text, max_retries=MAX_RETRIES):
    """G√©n√®re l'embedding d'un texte via Mistral avec retries en cas de rate limit."""
    for i in range(max_retries):
        try:
            response = client.embeddings.create(
                model="mistral-embed",
                inputs=[text]
            )
            return response.data[0].embedding
        except Exception as e:
            err_str = str(e)
            if "rate_limited" in err_str or "Service tier capacity" in err_str:
                wait = 2 ** i
                print(f"‚ö†Ô∏è Rate limit ou capacit√©, attente {wait}s... (retry {i+1}/{max_retries})")
                time.sleep(wait)
            else:
                print(f"‚ùå Erreur embedding : {e}")
                return None
    print(" √âchec apr√®s plusieurs retries")
    return None

# Fonction principale de g√©n√©ration des embeddings pour une colonne donn√©e
def generate_embedding_for_column(df, column_name, new_column_name):
    """G√©n√®re les embeddings pour une colonne sp√©cifique du DataFrame."""
    print(f"\n  G√©n√©ration des embeddings pour '{column_name}'...\n")

    # Cr√©e la colonne d'embeddings si absente
    if new_column_name not in df.columns:
        df[new_column_name] = [None] * len(df)

    for i in tqdm(range(len(df))):
        if pd.notna(df.loc[i, new_column_name]):
            continue  # d√©j√† calcul√©

        text = str(df.loc[i, column_name])
        if not text or text.lower() == "nan":
            df.at[i, new_column_name] = None
            continue

        # --- CHUNKING du texte ---
        chunks = text_splitter.split_text(text)

        # --- G√©n√®re un embedding pour chaque chunk ---
        chunk_embeddings = []
        for chunk in chunks:
            emb = embed_text(chunk)
            if emb:
                chunk_embeddings.append(emb)
            time.sleep(EMBED_SLEEP)  # Pause entre chaque requ√™te

        # --- Moyenne des embeddings des chunks ---
        if chunk_embeddings:
            avg_embedding = np.mean(chunk_embeddings, axis=0).tolist()
            df.at[i, new_column_name] = avg_embedding
        else:
            df.at[i, new_column_name] = None

        # --- Sauvegarde interm√©diaire ---
        if (i + 1) % BATCH_SAVE == 0:
            df.to_csv(OUTPUT_CSV, index=False)
            print(f" Sauvegarde interm√©diaire √† la ligne {i+1} ({column_name})")

    return df

# === Main === 
def main():
    df = pd.read_csv(INPUT_CSV)

    # V√©rification des colonnes n√©cessaires
    if 'description' not in df.columns:
        raise RuntimeError("Colonne 'description' introuvable dans le CSV")
    if 'description_longue' not in df.columns:
        raise RuntimeError("Colonne 'description_longue' introuvable dans le CSV")

    # Mode test : limite le nombre de lignes
    if MODE_TEST:
        df = df.head(TEST_SIZE)
        print(f" Mode TEST activ√© : traitement des {len(df)} premi√®res lignes")
    else:
        print(f" Mode COMPLET activ√© : traitement de {len(df)} lignes")

    # G√©n√©ration pour les deux colonnes
    df = generate_embedding_for_column(df, "description", "embedding_description")
    df = generate_embedding_for_column(df, "description_longue", "embedding_description_longue")

    # Sauvegarde finale
    df.to_csv(OUTPUT_CSV, index=False)
    print(f"\n‚úÖ Embeddings ajout√©s et sauvegard√©s dans {OUTPUT_CSV}")


if __name__ == "__main__":
    main()
